\chapter{Bayes' Theorem}

Let's say that that I am holding a bag of marbles in each of my hands.
You know that bag contains 60 white marbles and 40 red marbles. You
know that the other holds 10 white marbles and 90 red marbles. You
don't know which is which -- you can't see the marbles.

I hold out the bag in my left hands and ask ``What is the probability
that this is the bag that is mostly red marbles?'' You answer ``That
is the mostly-red-marbles bag with a probability of 0.5.  There is
also a 0.5 probability that it is the mostly-white-marbles bag.''

Then I let you pick one marble from the bag.  It is red. Now you must
update your beliefs. Clearly, it is more likely that this is the
mostly-red-marbles bag. What is the probability now?

Bayes Theorem gives you the rule for updating your beliefs based on
new data.

\section{Conditional Probability}

If you choose a person randomly off the street, you could ask,
``What is the probability that this person has a cough?''  In
mathematical notation, we might use the symbol $C$ to represent the
condition ``selected person has a cough'', so the quantity you are
interested in is $p(C)$, the probabililty that the person has a cough. \index{conditional probability}

If you choose the person from a doctor's waiting room, the probability
that the person has a cough is much higher. That is, given the fact
that the person is waiting to see a doctor, what is probability that
the person has a cough?  This is conditional probability: Given a
condition (like ``person is waiting to see a doctor'') what is the
probability of another condition (like ``person has a cough''). If we
use the symbol $D$ to represent ``person is waiting to see a doctor'',
we can express the conditional probability like this: $p(C | D)$, that
is the probability that the person has a cough, given that the person
is waiting to see a doctor.

What would be a good way to estimate $p(C | D)$ in this case? You
could go into a large doctors waiting room and count the people who
are waiting to see a docutor \textit{and} coughing and divide it by the number of all the people
who are waiting to see a doctor.  So we get one way to calculate conditional probability:

$$p( C | D) = \frac{ p(C \text{ AND } D)}{ p(D) }$$

That is, the probability that a person has cough, given that they are
waiting to see a doctor is equal to the probability that a person has
a cough \textit{and} is waiting to see a doctor divided by the
probability that a person is waiting to see a doctor (for any reason).

Note that this equation is equivalent to

$$p(C \text{ AND } D) = p(C | D) p(D)$$

You will see it in this form a lot.  In this case it says
``The probability that you are coughing and waiting to see a doctor is
equal to the probablity that you are waiting to see a doctor (for any reason) times the
probability that you are coughing, given that you are waiting to see a
doctor.''

We can also talk about $p(D | C)$, that is the probability that you
are waiting to see a doctor given that you have a cough. Notice that
this is different from $p(C | D)$, the probabilty that you have a
cough given that you are waiting to see a doctor.

Note that 

$$p(C \text{ AND } D) = p(D | C) p(C)$$

``The probability that you are coughing and waiting to see a doctor is
equal to the probablity that you are coughing (anywhere) times the
probability that you are waiting to see a doctor, given that you are
have a cough.''

Notice that we now have two ways to calculate $p(C \text{ AND } D)$:

$$p(D | C) p(C) = p(C \text{ AND } D) = p(C | D) p(D)$$

So

$$p(D | C) = \frac {p(C | D)p(D)}{P(C)}$$

Now you can calculate $p(D | C)$ (in this case, the probability that
you are waiting to see a doctor given that you have a cough.) if you
know:

\begin{itemize}
\item $p(C | D)$ (The probability that you have a cough given that you are waiting to see a doctor)
\item $p(D)$ (The probabilty that you are waiting for a doctor for any reason.)
\item $p(C)$ (The probability that you have a cough anywhere)
\end{itemize}

Pretty much all modern statistical methods (including most artificial
intelligence) are based on this formula, which is known as Bayes'
Theorem.  It was written down by Thomas Bayes before he died in
1761. It was found and published after his death.

\section{Using Bayes' Theorem}

Back to the example at the beginning. To review:

\begin{itemize}
\item There are two bags that look exactly the same.
\item Bag W has 60 white marbles and 40 red marbles.
\item Bag R has 10 white marbles and 90 red marbles.
\item You pull one marble from the selected bag -- it is red.
\end{itemize}

What is the probabilty that the selected bag is Bag R? Intuitively,
you know that the probability is now more than 0.5. What is the exact
number?

In terms of conditional probability, we say we are looking for ``the probability
that the selected bag is Bag R, given that you drew a red marble?'' or
$p(B_R | D_R)$, where $B_R$ is ``The selected bag is Bag R'' and $D_R$ is
``You drew a red marble from the selected bag''.

From Bayes' Theorem, we can write:

$$p(B_R | D_R) = \frac{ P(D_R | B_R) P(B_R) } {P(D_R)}$$

$P(D_R | B_R)$ is just the probability of drawing a red marble if the
selected bag is Bag R. That is easy to calculate: There are 100
marbles in the bag, and 90 are red.  Thus $P(D_R | B_R) = 0.9$.

$P(B_R)$ is just the probability that you chose Bag R before you drew
out a marble. Both bags look the same, so $P(B_R)= 0.5$.  This is
called \textit{the prior} because it represents what you thought the
probability was before you got more information.

$P(D_R)$ is the probabilty of drawing a red marble. There was 0.5
probability that you put your hand into Bag W (in which 40 of the 100
marbles are red) and a 0.5 probability that you put your hand into Bag
R (in which 90 of the 100 marbles are red).  So

$$P(D_R) = 0.5 \frac{40}{100} + 0.5 \frac{90}{100} = 0.65$$

Putting it together:

$$p(B_R | D_R) = \frac{ P(D_R | B_R) P(B_R) } {P(D_R)} = \frac{(0.9)(0.5)}{0.65} = \frac{9}{13} \approx 0.69$$

Thus, given that you have pulled a red marble, there is a 69\% chance
that you have selected the bag with 90 red marbles.

\section{Confidence}

Bayes' Theorem, then, is about updating your beliefs based on
evidence.  Before you drew out the red marble, you selected one bag
thinking it might contain 90 red marbles. How certain were you? You
were 0.5 certain, where 0.0 is complete disbelief and 1.0 is complete
confidence.  After pulling out the red marble, you were about 0.69
confident that you had chosen the bag with 90 red marbles.

The question ``How confident are you in your guess?'' is very
important in some situations. For example in medicine, diagnoses often
lead to risky interventions. Few diagnoses come with 100\% confidence.
All doctors should know how to use Bayes' Theorem.

In a trial, a jury is asked to determine if the accused person is
guilty of a crime. Few jurors at 100\% certain. In some trials, Bayes'
Theorem is a really important tool.

