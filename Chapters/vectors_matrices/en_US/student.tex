\chapter{Vectors and Matrices}

The last chapter provided an overview of linear algebra, using several image
examples. In this chapter, we will focus primarily on vector-matrix
multiplications. First, we will show how matrices can be used to represent a
set of linear equations. Then, we will provide you with a general definition
of vector-matrix multiplication, followed by a few examples. You will have an
opportunity to solve a problem manually, then by using Python. In this
chapter, we will use two-dimensional matrices for simplicity, but a matrix can
have any number of dimensions.
\index{matrices}
\section{Matrices}
We've been looking at vectors. We've seen them in physics as a straight line comprised of $x$ and $y$ components, or represented as a column of
numbers. For example, while we may write $\mathbf{v} = \left[ 1, 2, 3 \right]$
in line, the vector is really:
$$\mathbf{v} = \begin{bmatrix}
1\\
2\\
3
\end{bmatrix}$$

A matrix can be made of many columns, like the $3 \times 3$ matrix shown below:
$$\begin{bmatrix}
1 & 1 & 1\\
2 & 4 & 8\\
3 & 9 & 27
\end{bmatrix}$$
\index{matrices!vector in form of}
We describe the size and shape of matrices by saying \textit{an }$m \times
n$\textit{ matrix}, where $m$ is the number of \emph{rows} and $n$ is the number of
\emph{columns}. A \newterm{vector} is simply a one-column matrix. For example, the vectors
\textbf{v} above is of size$3 \times 1$. Matrices aren't restricted to 2 dimensions:
a matrix can be 3, 4, or any number of dimensions. For example, a $3 \times 2
\times 4$ matrix would be made of 4 stacked $3 \times 2$ matrices. Visually, however, that is hard to represent, and even worse to compute.

A matrix is considered \emph{square} when it has the same number of rows and columns. Most matrix operations have the restriction that the matrix must be square in order to perform operations, such as determinant calculation, finding an inverse, or eigenvector/eigenvalues, all of which you will learn in future chapters.3

\begin{Exercise}[title = {Matrix Dimensions 1}, label = mat_dim1]
Write the dimensions of the following matrices:
\begin{enumerate}
\item $\begin{bmatrix}
-3 & 0 & 4 & -2 & -4\\
-1 & 5 & 3 & 4 & -2\\
-3 & 2 & 3 & -5 & 1
\end{bmatrix}$
\item $\begin{bmatrix}
-3 & 1
\end{bmatrix}$
\item $\begin{bmatrix}
-3 & 2 & -3\\
4 & 0 & -3\\
-5 & -4 & 1\\
0 & -2 & 2\\
\end{bmatrix}$
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = mat_dim1]
\begin{enumerate}
\item $3 \times 5$
\item $1 \times 2$
\item $4 \times 3$
\end{enumerate}
\end{Answer}

\begin{Exercise}[title = {Matrix Dimensions 2}, label = mat_dim2]
Create a matrix with the indicated dimensions.
\begin{enumerate}
\item $1 \times 3$
\item $2 \times 4$
\item $4 \times 3$
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = mat_dim2]
\begin{enumerate}
\item The matrix should have 1 row and 3 columns. For example,
$$\begin{bmatrix}
1 & 2 & 3
\end{bmatrix}$$
\item The matrix should have 2 rows and 4 columns. For example,
$$\begin{bmatrix}
1 & 2 & 3 & 4\\
5 & 6 & 7 & 8
\end{bmatrix}$$
\item The matrix should have 4 rows and 3 columns. For example,
$$\begin{bmatrix}
1 & 2 & 3\\
4 & 5 & 6\\
7& 8 & 9\\
10 & 11 & 12
\end{bmatrix}$$
\end{enumerate}
\end{Answer}

\subsection{Zero Matrices}
Recall that we can represent a generic zero vector as $\textbf{0}$ or $\vec{0}$ (you may see both), which
indicates a vector of any number of dimensions filled with zeros. Just like
vectors, there are \textit{zero matrices}\index{zero matrix}, which can be any number of dimensions, all filled with zeros. 
In two dimensions, zero matrices are denoted as $\mathbf{\mathit{0}}_{m \times n}$, where the
subscript is the dimension of the matrix. The subscript can be expanded to
denote any number of dimensions.

\section{Operations of Matrices}
\subsection{Adding and Subtracting Matrices}
Matrices that are the same dimension can be added and subtracted. Just like
vectors, to add matrices you add the elements in the same position:
$$\begin{bmatrix}
-2 & -1\\
2 & 4
\end{bmatrix}
+ \begin{bmatrix}
5 & 2\\
-1 & -4
\end{bmatrix}
= \begin{bmatrix}
-2 + 5 & -1 + 2\\
2 + -1 & 4 + -4
\end{bmatrix} =
\begin{bmatrix}
3 & 1\\
1 & 0
\end{bmatrix}$$

And to subtract matrices, you subtract the elements in the same position:
$$\begin{bmatrix}
-2 & -1\\
2 & 4
\end{bmatrix}
- \begin{bmatrix}
5 & 2\\
-1 & -4
\end{bmatrix}
= \begin{bmatrix}
-2 - 5 & -1 - 2\\
2 - (-1) & 4 - (-4)
\end{bmatrix} =
\begin{bmatrix}
-7 & -3\\
3 & 8
\end{bmatrix}$$

Formally, for 2-dimensional matrices, we can say that:
\begin{mdframed}[style = important, frametitle={Adding and Subtracting Matrics}]
For two $m \times n$ matrices, the sum of the matrices is the matrix of the
sums of the elements in analogous positions:
$$\begin{bmatrix}
x_{11} & x_{12} & x_{13} & \cdots & x_{1n}\\
x_{21} & x_{22} & x_{23} & \cdots & \vdots\\
\vdots & \vdots & \vdots & \cdots & \vdots\\
x_{m1} & x_{m2} & x_{m3} & \cdots & x_{mn}
\end{bmatrix}
+ \begin{bmatrix}
y_{11} & y_{12} & y_{13} & \cdots & y_{1n}\\
y_{21} & y_{22} & y_{23} & \cdots & \vdots\\
\vdots & \vdots & \vdots & \cdots & \vdots\\
y_{m1} & y_{m2} & y_{m3} & \cdots & y_{mn}
\end{bmatrix} = $$
$$\begin{bmatrix}
x_{11} + y_{11} & x_{12} + y_{12} & x_{13} + y_{13} & \cdots & x_{1n} + y_{1n}\\
x_{21} + y_{21} & x_{22} + y_{22} & x_{23} + y_{23} & \cdots & \vdots\\
\vdots & \vdots & \vdots & \cdots & \vdots\\
x_{m1} + y_{m1} & x_{m2} + y_{m2} & x_{m3} + y_{m3} & \cdots & x_{mn} + y_{mn}
\end{bmatrix}$$

To subtract matrices, simply add the negative of the second matrix (that is,
\textbf{\textit{A}} - \textbf{\textit{B}} = \textbf{\textit{A}} + -\textbf{
\textit{B}}). Additionally, matrix addition is commutative (\textbf{\textit{A}}
+ \textbf{\textit{B}} = \textbf{\textit{B}} + \textbf{\textit{A}}).

Matrices of different dimensions cannot be added or subtracted. 
\end{mdframed}

\begin{Exercise}[title = {Adding and Subtracting Matrices}, label = add_mat]
Find \textbf{\textit{A}} + \textbf{\textit{B}}, \textbf{\textit{A}} -
\textbf{\textit{B}}, and \textbf{\textit{B}} - \textbf{\textit{A}}.
\begin{enumerate}
\item $\textbf{\textit{A}} = \begin{bmatrix}
0 & 4 & 0 & 5
\end{bmatrix}$ and $\textbf{\textit{B}} = \begin{bmatrix}
-2 & 3 & -2 & 5
\end{bmatrix}$
\item $\textbf{\textit{A}} = \begin{bmatrix}
4 & -4 & -2\\
1 & -3 & 5\\
-5 & 3 & 0
\end{bmatrix}$ and $\textbf{\textit{B}} = \begin{bmatrix}
5 & 0 & -1\\
-5 & -3 & -2\\
-5 & 3 & -4
\end{bmatrix}$.
\item $\textbf{\textit{A}} = \begin{bmatrix}
-2 & -1 & -5 & -1\\
5 & -4 & 4 & 3
\end{bmatrix}$ and $\textbf{\textit{B}} = \begin{bmatrix}
-5 & -2 & 3 & -5\\
0 & 5 & -4 & -3
\end{bmatrix}$.
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = add_mat]
\begin{enumerate}
\item \textbf{\textit{A}} + \textbf{\textit{B}} $= \begin{bmatrix}
-2 & 7 & -2 & 10
\end{bmatrix}$. $\textbf{\textit{A}} - \textbf{\textit{B}} = \begin{bmatrix}
2 & 1 & 2 & 0
\end{bmatrix}$. $\textbf{\textit{B}} - \textbf{\textit{A}} = \begin{bmatrix}
-2 & -1 & -2 & 0
\end{bmatrix}$
\item $\textbf{\textit{A}} + \textbf{\textit{B}} = \begin{bmatrix}
9 & -4 & -3\\
-4 & -6 & 3\\
-10 & 6 & -4
\end{bmatrix}$. $\textbf{\textit{A}} - \textbf{\textit{B}} = \begin{bmatrix}
-1 & -4 & -1\\
6 & 0 & 7\\
0 & 0 & 4
\end{bmatrix}$. $\textbf{\textit{B}} - \textbf{\textit{A}} = \begin{bmatrix}
1 & 4 & 1\\
-6 & 0 & -7\\
0 & 0 & -4
\end{bmatrix}$.
\item $\textbf{\textit{A}} + \textbf{\textit{B}} = \begin{bmatrix}
-7 & -3 & -2 & -6\\
5 & 1 & 0 & 0
\end{bmatrix}$. $\textbf{\textit{A}} - \textbf{\textit{B}} = \begin{bmatrix}
3 & 1 & -8 & 4\\
5 & -9 & 8 & 6
\end{bmatrix}$. $\textbf{\textit{B}} - \textbf{\textit{A}} = \begin{bmatrix}
-3 & -1 & 8 & -4\\
-5 & 9 & -8 & -6
\end{bmatrix}$.
\end{enumerate}
\end{Answer}

\subsection{Multiplying Matrices}
Matrix multiplication has dimensional limits.
We cannot multiply any two matrices; the first matrix must have the same
number of columns as the second has number of rows. Let's examine the origin
of the dimension limits on matrix multiplication. We begin with a review of
the vector dot product.

Recall that in order to find the dot product of two vectors, they must be the
same length (that is, the same number of dimensions). The result is always a
scalar: one number. You can review finding the dot product of vectors and
practice the dimension limits on the vector dot product in the next exercise.

\begin{Exercise}[title = {Vector Dot Product Review}, label = vect_dot]
Find all possible pairs of vectors that can be used to find a dot product,
then find the dot products.
\begin{enumerate}
\item $\mathbf{a} = \begin{bmatrix}
1\\
2
\end{bmatrix}$
\item $\mathbf{b} = \begin{bmatrix}
-3\\
3\\
5\\
-5
\end{bmatrix}$
\item $\mathbf{c} = \begin{bmatrix}
1\\
2\\
-1
\end{bmatrix}$
\item $\mathbf{d} = \begin{bmatrix}
-5\\
-1
\end{bmatrix}$
\item $\mathbf{e} = \begin{bmatrix}
1\\
-5\\
3\\
1
\end{bmatrix}$
\item $\mathbf{f} = \begin{bmatrix}
4\\
1\\
-3
\end{bmatrix}$
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = vect_dot]
It is possible to compute $\mathbf{a} \cdot \mathbf{d}$, $\mathbf{b} \cdot
\mathbf{e}$, and $\mathbf{c} \cdot \mathbf{f}$:
\begin{enumerate}
    \item $\mathbf{a} \cdot \mathbf{d} = 1(-5) + 2(-1) = -5 + (-2) = -7$
    \item $\mathbf{b} \cdot \mathbf{e} = -3(1) + 3(-5) + 5(3) + -5(1) = -3 +
    (-15) + 15 - 5 = -8$
    \item $\mathbf{c} \cdot \mathbf{f} = 1(4) + 2(1) + -1(-3) = 4 + 2 + 3 = 9$
\end{enumerate}
\end{Answer}

To multiply two matrices, it is helpful to think of the rows of the first
matrix and the columns of the second matrix as vectors. Let's see how this
shakes out for two $2 \times 2$ matrices in Figure~\ref{fig:mat_mult}:


% end paragraph
\medskip


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[] at (0,0) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \node[] at (-2.75, -1) {\textbf{\textit{A}}};
        \node[] at (-2, -1) {$\times$};
        \node[] at (-1, -1) {\textbf{\textit{B}}};
        \node[text = red] at (-3.8, 0.25) {$\mathbf{a}_1 \to$};
        \node[text = red] at (-3.8, -0.25) {$\mathbf{a}_2 \to$};
        \node[text = blue] at (-1.3, 0.7) {$\downarrow$};
        \node[text = blue] at (-1.3, 1) {$\mathbf{b}_1$};
        \node[text = blue] at (-0.55, 0.7) {$\downarrow$};
        \node[text = blue] at (-0.55, 1) {$\mathbf{b}_2$};
        \node[text = red] at (0.95, 0.15) {$\mathbf{a}_1$};
        \node[] at (1.2, 0.15) {$\cdot$};
        \node[text = blue] at (1.5, 0.15) {$\mathbf{b}_1$};
        \node[text = red] at (0.95, -0.25) {$\mathbf{a}_2$};
        \node[] at (1.2, -0.25) {$\cdot$};
        \node[text = blue] at (1.5, -0.25) {$\mathbf{b}_1$};
        \node[text = red] at (2.15, 0.15) {$\mathbf{a}_1$};
        \node[] at (2.4, 0.15) {$\cdot$};
        \node[text = blue] at (2.7, 0.15) {$\mathbf{b}_2$};
        \node[text = red] at (2.15, -0.25) {$\mathbf{a}_2$};
        \node[] at (2.4, -0.25) {$\cdot$};
        \node[text = blue] at (2.7, -0.25) {$\mathbf{b}_2$};
    \end{tikzpicture}
    \caption{Each entry in \textbf{\textit{C}}, $c_{ij}$, is the dot product
    of the $i^{th}$ row of \textbf{\textit{A}}, $a_i$, and the $j^{th}$ column
    of \textbf{\textit{B}}, $b_j$.}
    \label{fig:mat_mult}
\end{figure}



 Let's look at this more concretely. For two-dimensional matrices, it can be
 helpful to move your left index finger across the row and right index finger
 down the column, as shown in Figure~\ref{fig:fingers}.

 \begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[] at (0,3) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \draw[thick, -latex, red] (-3, 3.25) -- (-2, 3.25);
        \draw[thick, -latex, blue] (-1.25, 3.4) -- (-1.25, 2.6);
        \node[font = \tiny] at (1.25, 3.25) {
        \textcolor{red}{5}$\times$\textcolor{blue}{-1}$+$\textcolor{red}{4}$\times$\textcolor{blue}{-4}};

        \node[] at (0,2) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \draw[thick, -latex, red] (-3, 2.25) -- (-2, 2.25);
        \draw[thick, -latex, blue] (-.35, 2.4) -- (-.35, 1.6);
        \node[font = \normalsize] at (1.25, 2.25) {-21};
        \node[font = \tiny] at (2.25, 2.25) {
        \textcolor{red}{5}$\times$\textcolor{blue}{-2}$+$\textcolor{red}{4}$\times$\textcolor{blue}{-4}};

        \node[] at (0, 1) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \draw[thick, -latex, red] (-3, 0.75) -- (-2, 0.75);
        \draw[thick, -latex, blue] (-1.25, 1.4) -- (-1.25, 0.6);
        \node[font = \normalsize] at (1.25, 1.25) {-21};
        \node[font = \normalsize] at (2.25, 1.25) {-26};
        \node[font = \tiny] at (1.25, 0.8) {
        \textcolor{red}{-5}$\times$\textcolor{blue}{-1}$+$\textcolor{red}{1}$\times$\textcolor{blue}{-5}};

        \node[] at (0,0) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \draw[thick, -latex, red] (-3, -0.25) -- (-2, -0.25);
        \draw[thick, -latex, blue] (-.35, 0.4) -- (-.35, -0.4);
        \node[font = \normalsize] at (1.25, 0.25) {-21};
        \node[font = \normalsize] at (2.25, 0.25) {-26};
        \node[font = \normalsize] at (1.25, -0.25) {0};
        \node[font = \tiny] at (2.25, -0.25) {
        \textcolor{red}{-5}$\times$\textcolor{blue}{-2}$+$\textcolor{red}{1}$\times$\textcolor{blue}{-4}};
        \node[] at (0,-1) {$\begin{bmatrix}
            5 & 4\\
            -5 & 1
        \end{bmatrix} \times \begin{bmatrix}
            -1 & -2\\
            -5 & -4
        \end{bmatrix} = \begin{bmatrix}
             & & & & & & & \\
             & & & & & & &
        \end{bmatrix}$};
        \node[font = \normalsize] at (1.25, -0.75) {-21};
        \node[font = \normalsize] at (2.25, -0.75) {-26};
        \node[font = \normalsize] at (1.25, -1.25) {0};
        \node[font = \normalsize] at (2.25, -1.25) {6};
    \end{tikzpicture}
    \caption{You can use your fingers to trace across matrix \textbf{\textit{A}}
    and down matrix \textbf{\textit{B}} to find $\textbf{\textit{A}} \cdot
    \textbf{\textit{B}}$.}
    \label{fig:fingers}
\end{figure}

Since each entry in the product matrix is the dot product between a row of the
first matrix and a column of the second matrix, the first matrix must have the
same number of elements in each row as the second has in each column. Another
way to say this is that the number of columns of the first matrix must match
the number of rows in the second matrix.

\begin{mdframed}[style = important, frametitle = {Matrix Multiplication}]
For two-dimensional matrices, the inner dimensions must match in order to
carry out matrix multiplication. 
That is, if we want to find \textbf{\textit{
A}}$\times$\textbf{\textit{B}}, and \textbf{\textit{A}} has dimensions $m
\times n$, then \textbf{\textit{B}} must have dimensions $n \times p$, where
$m$, $n$, and $p$ are integers. The resulting matrix will have dimensions $m
\times p$ ($m$ and $p$ may be equal or unequal). Note that we use $\times$ to differentiate from the dot product, represented by $\cdot$. 
\end{mdframed}

\begin{Exercise}[title = {Multiplying Matrices 1}, label = mult_mat1]
Multiply the matrices.
\begin{enumerate}
\item $\begin{bmatrix}
-5 & -2 & 2 & 1
\end{bmatrix} \times \begin{bmatrix}
-3 & -1 & -5\\
3 & 0 & 3\\
4 & -1 & -4\\
-1 & -4 & 2
\end{bmatrix}$
\item $\begin{bmatrix}
1\\
5\\
-5\\
4\\
1
\end{bmatrix} \times \begin{bmatrix}
0 & 5 & 1
\end{bmatrix}$
\item $\begin{bmatrix}
-1 & 4 & -4\\
5 & -3 & 5\\
-1 & -4 & 4\\
-4 & 1 & 4
\end{bmatrix} \times \begin{bmatrix}
-3 & 5 & 1\\
-3 & 0 & -3\\
0 & 3 & 0
\end{bmatrix}$
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = mult_mat1]
\begin{enumerate}
    \item $\begin{bmatrix}
        -2 & -1 & 5
    \end{bmatrix}$
    \item $\begin{bmatrix}
        0 & 5 & 1\\
        0 & 25 & 5\\
        0 & -25 & -5\\
        0 & 20 & 4\\
        0 & 5 & 1
    \end{bmatrix}$
    \item $\begin{bmatrix}
        -9 & -17 & 11\\
        -6 & 40 & -4\\
        15 & 7 & -13\\
        9 & -8 & -1
    \end{bmatrix}$
\end{enumerate}
\end{Answer}

\begin{Exercise}[title = {Multiplying Matrices 2}, label = mult_mat2]
Find $\mathbf{\mathit{A}} \times \mathbf{\mathit{B}}$ and $\mathbf{\mathit{B}} \times \mathbf{\mathit{A}}$.
\begin{enumerate}
\item $\mathbf{\mathit{A}} = \begin{bmatrix}
-2\\
2\\
1\\
-2
\end{bmatrix}$ and $\mathbf{\mathit{B}} = \begin{bmatrix}
-4 & 3 & -5 & -2
\end{bmatrix}$
\item $\mathbf{\mathit{A}} = \begin{bmatrix}
-4 & -2\\
2 & 5\\
-3 & -4\\
\end{bmatrix}$ and $\mathbf{\mathit{B}} = \begin{bmatrix}
0 & -2 & -4\\
1 & -4 & 0
\end{bmatrix}$
\item $\mathbf{\mathit{A}} = \begin{bmatrix}
2 & 0 & 1 & 4\\
-4 & 0 & -5 & -1
\end{bmatrix}$ and $\mathbf{\mathit{B}} = \begin{bmatrix}
0 & -3\\
-4 & -1\\
-2 & 3\\
-5 & 1
\end{bmatrix}$
\end{enumerate}
\end{Exercise}

\begin{Answer}[ref = mult_mat2]
\begin{enumerate}
\item $\mathbf{\mathit{A}} \times \mathbf{\mathit{B}} = \begin{bmatrix}
8 & -6 & 10 & 4\\
-8 & 6 & -10 & -4\\
-4 & 3 & -5 & -2\\
8 & -6 + 1- & 4
\end{bmatrix}$ and $\mathbf{\mathit{B}} \times \mathbf{\mathit{A}} =
\begin{bmatrix}
13
\end{bmatrix}$
\item $\mathbf{\mathit{A}} \times \mathbf{\mathit{B}} = \begin{bmatrix}
-2 & 16 & 16\\
5 & -24 & -8\\
-4 & 22 & 12
\end{bmatrix}$ and $\mathbf{\mathit{B}} \times \mathbf{\mathit{A}} =
\begin{bmatrix}
8 & 6\\
-12 & -22
\end{bmatrix}$
\item $\mathbf{\mathit{A}} \times \mathbf{\mathit{B}} = \begin{bmatrix}
-22 & 1\\
15 & -4
\end{bmatrix}$ and $\mathbf{\mathit{B}} \times \mathbf{\mathit{A}} =
\begin{bmatrix}
12 & 0 & 15 & 3\\
-4 & 0 & 1 & -15\\
-16 & - & -17 & -11\\
-14 & 0 & -10 & -21
\end{bmatrix}$
\end{enumerate}
\end{Answer}

What have you noticed about the results of $\mathbf{\mathit{A}} \times
\mathbf{\mathit{B}}$ as compared to $\mathbf{\mathit{B}} \times \mathbf{
\mathit{A}}$? You should have noticed that the product matrices are
\textit{different dimensions}. This leads us to the next unusual property of
matrix multiplication: it is \textit{non-commutative}. That is, the \textit{
order} in which you multiply matrices affects the result. This is very
different from scalar values!

As you saw in the second matrix multiplication exercise, \textbf{\textit{A}}
is a $2 \times 4$ matrix and \textbf{\textit{B}} is a $4 \times 2$ matrix,
then \textbf{\textit{A}}\textbf{\textit{B}} is a $2 \times 2$ matrix, while
\textbf{\textit{B}}\textbf{\textit{A}} is a $4 \times 4$ matrix. It is obvious,
then, that $\mathbf{\mathit{A}} \cdot \mathbf{\mathit{B}} \neq \mathbf{\mathit{
B}} \cdot \mathbf{\mathit{A}}$. What if \textbf{\textit{A}} and \textbf{\textit{
B}} are square matrices?

\begin{Exercise}[title=Are Matrices Commutative?,label=mult_mat3]
    Find $\mathbf{\mathit{A}} \cdot \mathbf{\mathit{B}}$ and
    $\mathbf{\mathit{B}} \cdot \mathbf{\mathit{A}}$ if $\mathbf{\mathit{A}} =
    \begin{bmatrix}
    -3 & 5\\
    -1 & 0
    \end{bmatrix}$ and $\mathbf{\mathit{B}} = \begin{bmatrix}
    -1 & 1\\
    4 & -3
    \end{bmatrix}$.
\end{Exercise}
\begin{Answer}[ref=mult_mat3]
    $$\mathbf{\mathit{A}} \times \mathbf{\mathit{B}} =
    \begin{bmatrix}
    -3 & 5\\
    -1 & 0
    \end{bmatrix} \cdot \begin{bmatrix}
    -1 & 1\\
    4 & -3
    \end{bmatrix} = \begin{bmatrix}
    -3(-1) + 5(4) & -3(1) + 5(-3)\\
    -1(-1) + 0(4) & -1(1) + 0(-3)
    \end{bmatrix} = \begin{bmatrix}
    23 & -18\\
    1 & -1
    \end{bmatrix}$$
    $$\mathbf{\mathit{B}} \times \mathbf{\mathit{A}} = \begin{bmatrix}
    -1 & 1\\
    4 & -3
    \end{bmatrix} \cdot \begin{bmatrix}
    -3 & 5\\
    -1 & 0
    \end{bmatrix} = \begin{bmatrix}
    -1(-3) + 1(-1) & -1(5) + 1(0)\\
    4(-3) + -3(-1) & 4(5) + -3(0)
    \end{bmatrix} = \begin{bmatrix}
    2 & -5\\
    -9 & 20
    \end{bmatrix}$$
\end{Answer}


As you can see, even if \textbf{\textit{A}} and \textbf{\textit{B}} are square,
matrix multiplication is still not commutative.

\begin{mdframed}[style = important, frametitle = {Non-Commutation of Matrix Multiplication}]
For two matrices \textbf{\textit{A}} and \textbf{\textit{B}}, where neither is
an identity matrix or a zero matrix:
$$\mathbf{\mathit{A}} \times \mathbf{\mathit{B}} \neq \mathbf{\mathit{B}}
\times \mathbf{\mathit{A}}$$
\end{mdframed}

\subsubsection{Properties of the Zero Matrix}
Just like the number 0, the zero matrix, \textbf{\textit{0}} has unique
mathematical properties:
\begin{mdframed}[style = important, frametitle = {Properties of the Zero Matrix}]
For a matrix, \textbf{\textit{A}}, and a zero matrix, \textbf{\textit{0}}
\begin{enumerate}
\item $\mathbf{\mathit{A}} + \mathbf{\mathit{0e}} = \mathbf{\mathit{A}}$
\item $\mathbf{\mathit{A}} + \mathbf{\mathit{-A}} = \mathbf{\mathit{0e}}$
\item $0 \cdot \mathbf{\mathit{A}} = \mathbf{\mathit{0e}}$
\end{enumerate}
\end{mdframed}

\subsubsection{The Identity Matrix}
There is another special matrix, called the \textit{identity matrix}\index{
identity matrix}, usually denoted with \textbf{\textit{I}}. An identity matrix
is all zeroes except for a diagonal line of ones. A $3 \times 3$ identity
matrix is shown below:

$$\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}$$

All identity matrices are square (that is, they have the same number of rows
as they do columns). The identity matrix has the special property that
whenever a vector or matrix is multiplied by \textbf{\textit{I}}, it doesn't
change. Let's look at some examples:

\textbf{Example}: If $\mathbf{x} = \begin{bmatrix}
2\\
-3
\end{bmatrix}$, what is $\mathbf{\mathit{I}}\mathbf{x}$? (Take \textbf{\textit{
I}} to be a $2 \times 2$ identity matrix.)

\textbf{Solution}: $$\mathbf{\mathit{I}} \mathbf{x} = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \cdot \begin{bmatrix}
2 \\
-3
\end{bmatrix} = \begin{bmatrix}
1 \cdot (2) + 0 \cdot (-3)\\
0 \cdot (2) + 1 \cdot (-3)
\end{bmatrix} = \begin{bmatrix}
2\\
-3
\end{bmatrix}$$

\textbf{Example}: If $\mathbf{\mathit{B}} = \begin{bmatrix}
-2 & 5\\
3 & -4
\end{bmatrix}$, what is $\mathbf{\mathit{I}} \times \mathbf{\mathit{B}}$?

\textbf{Solution}: $$\mathbf{\mathit{I}} \times \mathbf{\mathit{B}} =
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \cdot \begin{bmatrix}
-2 & 5\\
3 & -4
\end{bmatrix} = \begin{bmatrix}
1 \cdot (-2) + 0 \cdot (5) & 1 \cdot (5) + 0 \cdot (-4)\\
0 \cdot (-2) + 1 \cdot (5) & 0 \cdot (5) + 1 \cdot (-4)
\end{bmatrix} = \begin{bmatrix}
-2 & 5\\
3 & -4
\end{bmatrix}$$

\begin{mdframed}[style = important, frametitle = {Properties of the Identity Matrix}]
An $n \times n$ identity matrix, \textbf{\textit{I}}, does not change any
vectors or matrices it multiplies. That is:
\begin{enumerate}
\item $\mathbf{\mathit{I}} \times \mathbf{x} = \mathbf{x}$
\item $\mathbf{\mathit{I}} \times \mathbf{\mathit{B}} = \mathbf{\mathit{B}}$
\end{enumerate}
where \textbf{x} is an $n \times 1$ vector and \textbf{\textit{B}} is an $n
\times p$ matrix ($p$ may be, but is not necessarily, equal to $n$).
\end{mdframed}


\subsection{Transposing a Matrix}
% FIXME add https://en.wikipedia.org/wiki/Transpose#Implementation_of_matrix_transposition_on_computers
\index{matrix transpose}

The \textbf{transpose} of a matrix is an operation that flips a matrix over its diagonal. In other words, rows become columns and columns become rows. If a matrix $A$ has entries $a_{ij}$, then its transpose, written $A^\top$, sometimes $A^T$, has entries $a_{ji}$.

\begin{mdframed}[style = important, frametitle = {Transpose of a Matrix}]
If
\[
A =
\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix},
\]
then the \textbf{Transpose of A} is
\[
A^T =
\begin{bmatrix}
a_{11} & a_{21} & \cdots & a_{m1} \\
a_{12} & a_{22} & \cdots & a_{m2} \\
\vdots & \vdots & \ddots & \vdots \\
a_{1n} & a_{2n} & \cdots & a_{mn}
\end{bmatrix}.
\]
That is, entry $a_{ij}$ becomes $a_{ji}$.
\end{mdframed}

\textbf{Example:}
Let
\[
A =
\begin{bmatrix}
2 & -1 & 4 \\
0 & 3 & 5
\end{bmatrix}.
\]

Then the transpose of $A$ is
\[
A^\top =
\begin{bmatrix}
2 & 0 \\
-1 & 3 \\
4 & 5
\end{bmatrix}.
\]

Notice how the first \emph{row} of $A$ becomes the first \emph{column} of $A^\top$, and so on.

\subsection{Properties of Transposes}

The transpose operation behaves nicely with matrix addition and multiplication:
\begin{enumerate}[label=(\arabic*)]
    \item 
    \item $(A^T)^T = A$
    \item \((A + B)^T = A^T + B^T\)
    \item \((cA)^T = cA^T\) for any scalar $c$
    \item \((ABC)^T = C^T B^T A^T\) (order reverses)
    
\end{enumerate}
Property 4 is especially important and often surprises studentsâ€”the transpose of a product reverses the order.

Transposing a matrix is used throughout linear algebra, especially when:
\begin{itemize}
    \item converting rows into column vectors (and vice versa),
    \item defining dot products using matrix multiplication,
    \item forming symmetric matrices \((A = A^T)\),
    \item working with orthogonal matrices \((Q^T Q = I)\),
\end{itemize}

$$\begin{bmatrix}
1 & 2 & 3\\
4 & 5 & 6 
\end{bmatrix}
$$

More generally, a matrix with $m$ rows and $n$ columns is referred to as an $m \times n$ matrix, or simply an $m$-by-$n$ matrix; $m$ and $n$ are its dimensions.

The general form of a $2 \times 3$ matrix $A$ is:
$$
A = \begin{bmatrix}
a_{1,1} & a_{1,2} & a_{1,3} \\
a_{2,1} & a_{2,2} & a_{2,3}
\end{bmatrix}
$$

\section{Types of Matrices}
\index{matrices!shapes of}

Matrices can be described by their shape:
\begin{description}
    \item[\textbf{Row Matrix}] A matrix of size $1\times n$ with $1$ row and $n$ columns.
    \item[\textbf{Column Matrix}] A matrix of size $n\times 1$ with $n$ rows and $1$ column, typically used to represent vectors. 
    \item[\textbf{Square Matrix}] A matrix of size $n\times n$, containing the same number of rows and columns
    \item[\textbf{Rectangular Matrix}] A matrix of size $m \times n$, that has an unequal number of rows and columns.
    
\end{description}
\index{matrices!properties of}
They can also be described by their unique numerical properties. Special matrices that come in handy for certains types of computations. These are a few of the most common special matrices:
\begin{description}
	\item[\textbf{Zero Matrix}] A matrix that only contains entries that are zero. $$\vecb{0 & 0 \\ 0 & 0}$$ The matrix above could also be $$0_{2\times 2}$$
       \item[\textbf{Diagonal Matrix}] A square matrix with nonzero entries along the diagonal, and zeroes everywhere else. $$\vecb{2 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 6}$$
	\item[\textbf{Identity Matrix}] A diagonal matrix with entries of 1 along the diagonal. $$\vecb{1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1}$$
	\item[\textbf{Symmetric Matrix}] A Symmetric matrix is a matrix, when transposed, becomes itself.
	$$
       A = \begin{bmatrix}
       20 & 40 & 60 \\
       40 & 50 & 80 \\
       60 & 80 & 100
       \end{bmatrix}
       $$
	\item[\textbf{Triangular Matrix}] This is a special square matrix that can be upper triangular or lower triangular. If upper, the main diagonal and all entries above it are nonzero while the lower entries are all zero. If lower, the main diagonal and all the entries below it are nonzero, while the upper entries are all zero. A matrix that is both upper and lower triangular becomes a diagonal matrix.
	
       Upper Triangular Matrix
       $$
       \begin{bmatrix}
       2 & 3 & 1 \\
       0 & 5 & 4 \\
       0 & 0 & 6
       \end{bmatrix}
       $$
       Lower Triangular matrix
       $$
       \begin{bmatrix}
       7 & 0 & 0 \\
       2 & 5 & 0 \\
       4 & 3 & 9
       \end{bmatrix}
       $$
\end{description}

\subsection{Symmetric Matrices}
\index{symmetric matrices}
If you want to find out if a square matrix is symmetric, you need to transpose it. If the transpose is equal to the original matrix, then the matrix is symmetric.

To transpose a matrix, flip it over its diagonal so that the rows and columns are switched, like this:
$$
A = \begin{bmatrix}
a_{1,1} & a_{1,2} & a_{1,3} \\
a_{2,1} & a_{2,2} & a_{2,3} \\
a_{3,1} & a_{3,2} & a_{3,3}
\end{bmatrix}
$$
After transposing:
$$
A^T = \begin{bmatrix}
a_{1,1} & a_{2,1} & a_{3,1} \\
a_{1,2} & a_{2,2} & a_{3,2} \\
a_{1,3} & a_{2,3} & a_{3,3}
\end{bmatrix}
$$
Note that $A^T$ means the transpose of A. 

Let's see how this works for the following square matrix, A.
$$
A = \begin{bmatrix}
1 & 2 & 3 \\
2 & 4 & 5 \\
3 & 5 & 6
\end{bmatrix}
$$
Switch the rows and columns to get the transpose:
$$
A^T = \begin{bmatrix}
1 & 2 & 3 \\
2 & 4 & 5 \\
3 & 5 & 6
\end{bmatrix}
$$
Notice that $A = A^T$, so the matrix is symmetric.

What about matrix B? 
$$
B = \begin{bmatrix}
1 & 2 & 3 \\
2 & 4 & 5 \\
7 & 8 & 9
\end{bmatrix}
$$
Switch the rows and columns to get the transpose:
$$
B = \begin{bmatrix}
1 & 2 & 7 \\
2 & 4 & 8 \\
3 & 5 & 9
\end{bmatrix}
$$

Note that $B \neq B^T$, so B is not symmetrical.

\begin{Exercise}[title={Matrix Transposition}, label=matrix-transpose01]
Find the transpose of this matrix. Is it symmetric? 
$$A = \begin{bmatrix}
 		3 & -2 &4  \\
 		-2 & 6 &2 \\
 		4 & 2 & 3 
	  \end{bmatrix}$$
\end{Exercise}
\begin{Answer}[ref=matrix-transpose01]
$$A =  A^t = 
	  \begin{bmatrix}
 		3 & -2 & 4  \\
 		-2 & 6 & 2 \\
 		4 & 2 & 3 
	\end{bmatrix}$$
\end{Answer}

\subsection{Can We Divide Matrices?}
Matrices cannot be divided. Suppose we have a matrix, \textbf{\textit{A}}, a vector \textbf{x}, and another vector \textbf{b} such that:

$$\textbf{\textit{A}} \cdot \textbf{x} = \textbf{b}$$

Now, if we know \textbf{\textit{A}} and \textbf{x}, it is easy to find \textbf{b}. What if, on the other hand, we know \textbf{\textit{A}} and \textbf{b} and want to find \textbf{x}? We might be tempted to do something like this:

$$\textbf{x} = \frac{\textbf{b}}{\textbf{\textit{A}}}$$

While this would be correct if \textbf{x}, \textbf{b}, and \textbf{\textit{A}} were scalars, but it is not for matrices. However, there is an analogy we can make. Instead of trying to divide by \textbf{\textit{A}}, we can multiply by its \textit{inverse}:

\begin{mdframed}[style = important, frametitle = {Inverse Matrices}]
Given a matrix \textbf{\textit{A}}, and vectors \textbf{b} and \textbf{x}, if

$$\textbf{\textit{A}} \times \textbf{x} = \textbf{b}$$

Then,

$$\textbf{x} = \textbf{\textit{A}}^{-1} \times \textbf{b}$$
\end{mdframed}

$\textbf{\textit{A}}^{-1}$ is called the \textit{inverse matrix}. \emph{But}, the inverse \emph{does not always exist}! We will explore inverse matrices and how to find them in the next chapter.\index{inverse matrix}

% https://www.youtube.com/watch?v=HgFUYepT7FM
% https://www.youtube.com/watch?v=P5GJJ02OG08