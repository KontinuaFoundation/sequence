\chapter{Vector Spans and Independence}

A vector span is the collection of vectors obtained by scaling and combining the original set of vectors in all possible proportions.  Formally, if the set $S = \{v_1, v_2, ..., v_n\}$ contains vectors from a vector space $V$, then the span of $S$ is given by:

\begin{equation}
{Span}(S) = \{a_1v_1 + a_2v_2 + ... + a_nv_n : a_1, a_2, ..., a_n \in \mathbb{R}\}
\end{equation}

This means that any vector in the Span$(S)$ can be written as a linear combination of the vectors in $S$.

Vector spans have practical applications in a number of fields. Computer graphics and physics are only two of them. For example, in space travel, knowing the vector span is essential to calculating a slingshot maneuver that will give spacecraft a gravity boost from a planet. For this, you'd need to know the gravity vector of the planet relative to the sun and the velocity vectors that characterize the spacecraft. Engineers would use this information to figure out the trajectory angle that would allow the spacecraft to achieve a particular velocity in the desired direction. 

For a discussion of linear combinations and vector span, view this Khan Academy video: https://rb.gy/g1snk

\section{Vector Independence}

A set of vectors $S = \{v_1, v_2, ..., v_n\}$ is  linearly independent if the only solution to the equation $a_1v_1 + a_2v_2 + ... + a_nv_n = 0$.

is $a_1 = a_2 = ... = a_n = 0$. This means that no vector in the set can be written as a linear combination of the other vectors.

If there exists a nontrivial solution (i.e., a solution where some $a_i \neq 0$), then the vectors are said to be linearly dependent. This means that at least one vector in the set can be written as a linear combination of the other vectors.

The concept of vector independence is fundamental to the study of vector spaces, bases, and rank. You'll learn more about these concepts in future modules. 

\subsection{Dependent Vectors}
Let's start by looking at two vectors. 

$$v_1 = \begin{bmatrix}
			2 \\
			4
		\end{bmatrix}$$
$$v_2 = \begin{bmatrix}
			-14 \\
			-28
\end{bmatrix}$$

These two vectors are dependent because $v_2 = -7*v_2$. This is an obvious example but let's show it mathematically. If linearly independent, the two vectors must satisfy:

	$$v_1a_1 + v_1a_2 = 0$$
	$$v_2a_1 + v_2a_2 = 0$$

which is:
	$$2a_1 -14a_2 = 0$$
	$$4a_1 -28a_2 = 0$$

To solve, multiply the top equation by -2 and add it to the bottom: 
$$2a_1 -14a_2 = 0 $$
$$ 0  + 0     = 0 $$

The bottom equation drops out. Now  olve for $a_1$ in the remaining equation:
$$a_1 = -7a_2$$
As you can see, one vector is a multiple of another. $$a_1 \neq a_2 \neq 0$$

\subsection{Independent Vectors}
Let's see if these two vectors are independent.
$$v_1 = \begin{bmatrix}
1 \\
0
\end{bmatrix}$$
$$v_2 = \begin{bmatrix}
0 \\
-1
\end{bmatrix}$$

To be independent,the two vectors must satisfy:
	$$v_1a_1 + v_1a_2 = 0$$
	$$v_2a_1 + v_2a_2 = 0$$
	
which is:
$$\begin{bmatrix}
	a_1 + 0*a_2 \\
	0*a_1 + a_2
\end{bmatrix}$$

So:
$a_1 = a_2 = 0$
These vectors are not only independent, but they are orthogonal (perpendicular) to one another. You'll learn more about orthogonality later.

Here is an example whose solution isn't as obvious. You can solve using Gaussian elmination.
$$v_1 = [2,1]$$
$$v_2 = [1,-6]$$

Rewrite as a system of equations:
$$
	a_1*2 + a_2*1 = 0 
	a_1*1 + a_2*(-6) = 0
$$
First swap the equations to that the the top equation has a coefficient of 1 for $a_1$:
$$
	a_1 - 6a_2 = 0 
	2a_1 + a_2 = 0 
$$
Next multiply row 1 by -2 and add it to row 2:
$$
	a_1 - 6a_2 = 0 
	0  - 11a_2 = 0 
$$
Multiply row 2 by 1 divided by 11.
$$
	a_1 - 6a_2 = 0 
	0  +  a_2 = 0 
$$
Back substitute $a_2$ solution into the first equation:
$$
	a_1  = 0 
	a_2 = 0 
$$
Therefore $$a_1 = a_2 = 0$$ and the two vectors are linearly independent.

\begin{Exercise}[title={Vector Independence}, label=vector_independence]
    Are these vectors independent? 
    \begin{itemize}
    \item $[2, 1, 4]$
    \item $[2, -1, 2]$ 
    \item $[0, 1, -2]$
    \end{itemize}
    Show your work.
\end{Exercise}

\begin{Answer}[ref=vector_independence]
    Rewrite as a system of equations:
        $$\begin{matrix}
			2*a_1 +2*a_2 + 0*a_3 = 0 \\
			1*a_1 - 1*a_2 +1*a_3 = 0 \\
			4*a_1 + 2*a_2 - 2*a_3 = 0
		\end{matrix} $$
	Simplify
		$$\begin{matrix}
			2a_1 +2*a_2  = 0 \\
			a_1 - a_2 + a_3 = 0 \\
			4a_1 + 2a_2 - 2a_3 = 0
		\end{matrix} $$
	Swap row 2 and 1:
	$$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			2a_1 +2*a_2  = 0 \\
			4a_1 + 2a_2 - 2a_3 = 0
		\end{matrix} $$
	Multiply row 1 by -2 and add to row 2:
	$$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			0 +  3*a_2 -2a_3    = 0 \\
			4a_1 + 2a_2 - 2a_3 = 0
		\end{matrix} $$
	Multiply row 1 by -4 and add to row 3:	
	$$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			0 +   3*a_2 -2a_3    = 0 \\
			0   + 6a_2 - 6a_3 = 0
		\end{matrix} $$
	Multiply row 2 by -4 and add to row 3:
	$$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			0 +   3*a_2 -2a_3    = 0 \\
			0   + 0   - 2a_3 = 0
		\end{matrix} $$
	Multiply row 3 by -1 and add to row 2:
	$$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			0 +   3*a_2 +0    = 0 \\
			0   + 0   - 2a_3 = 0
		\end{matrix} $$
    Divide row 3 by -2 and row 2 by $\frac{1}{3}$:
    $$\begin{matrix}
			a_1 - a_2 + a_3 = 0 \\
			0 +   a_2 +0    = 0 \\
			0   + 0   a_3 = 0
		\end{matrix} $$
	Backsubstitute $a_2$ and $a_3$ into row 1:
	 $$\begin{matrix}
			a_1 +0 + ) = 0 \\
			0 +   a_2 +0   = 0 \\
			0   + 0   a_3 = 0
		\end{matrix} $$
	 Therefore $$a_1 = a_2 = a_3 = 0$$.
\end{Answer}
    
    
    